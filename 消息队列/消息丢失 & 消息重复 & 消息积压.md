### 检测消息丢失
- 利用消息队列有序性验证是否有消息丢失
	- Producer 消息附加连续递增的序号
	- Consumer 端检查序号是否连续 
	- 注意
		- Kafka 和 RocketMQ 不保证 Topic 上严格顺序，只能保证分区/队列上的消息有序
		- 发消息是必须指定分区/队列，且每个分区/队列单独检测
		- 如果 Producer 多实例，Producer 分别生成各自的消息序号，并且附上Producer 标识
		- 最好 Consumer 实例和 分区数量一直，方便检测序号有序性

### 确保消息可靠传递
一条消息从生产到消费完成的过程，可以分为三个阶段：

![](https://mynoteimage.oss-cn-beijing.aliyuncs.com/note/2022-03-22-153830.jpg)

- 生产阶段：消息在 Producer 创建，网络传输发送到 Broker
	- 通过请求确认机制，保证消息的可靠传递
	- Producer（客户端） 发送给 Broker 消息后， Broker 会返回客户端一个确认响应
	- 代码需要 catch 异常进行处理
- 存储阶段：消息在 Broker 端存储，如果是集群，消息会在这个阶段复制到其他副本上
	- 
- 消费阶段：Consumer 从 Broker 上拉取信息，网络传输到 Consumer 
	- 不在收到消息后发送消费确认，而是在业务逻辑执行完后确认

### 重复消息
- 幂等性
	- 利用数据库唯一约束
	- Redis SETNX
- 为更新的数据设置前置条件
- 记录并检查操作
	- 使用全局唯一 ID 附加在消息中

### 消息积压
- 优化性能
	- 发送端性能优化
	- 消费端性能优化
		- 水平扩容
			- 在扩容 Consumer 的实例数量的同时，必须同步扩容主题中的分区（也叫队列）数量，确保 Consumer 的实例数和分区数量是相等的
